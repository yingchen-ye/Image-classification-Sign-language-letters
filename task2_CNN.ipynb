{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. IMPORTING INITIAL NECESSARY LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. DATA PREPERATION / PREPROCESSING\n",
    "\n",
    "#2.1 Importing the dataset:\n",
    "with np.load('train_data_label.npz') as data:\n",
    "    X_train = data['train_data']\n",
    "    Y_train = data['train_label']\n",
    "\n",
    "with np.load('test_data_label.npz') as data:\n",
    "    X_test = data['test_data']\n",
    "    Y_test = data['test_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20591, 784) (20591,) (6864, 784) (6864,) (7172, 784) (7172,)\n",
      "(20591, 28, 28, 1)\n",
      "(6864, 28, 28, 1)\n",
      "(7172, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#2.3 Splitting the training data set into a training and validation set:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.25, random_state = 999)\n",
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape)\n",
    "\n",
    "#2.4 Reshaping the data:\n",
    "X_train = X_train.reshape(-1, 28,28, 1)\n",
    "print(X_train.shape)\n",
    "\n",
    "X_val = X_val.reshape(-1, 28, 28, 1)\n",
    "print(X_val.shape)\n",
    "\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "print(X_test.shape)\n",
    "\n",
    "#2.5 Converting the labels to binary form:\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "Y_train = lb.fit_transform(Y_train)\n",
    "Y_val = lb.fit_transform(Y_val)\n",
    "Y_test = lb.fit_transform(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. BUILDING THE CNN MODEL\n",
    "\n",
    "#3.1 Convolution layers:\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size = (5, 5),\n",
    "                 strides = 1, padding = 'same', activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(MaxPool2D(pool_size = (3, 3), strides = 2, padding = 'same'))\n",
    "model.add(Conv2D(64, kernel_size = (2, 2),\n",
    "                strides = 1, activation = 'relu', padding = 'same'))\n",
    "model.add(MaxPool2D((2, 2), 2, padding = 'same'))\n",
    "model.add(Conv2D(32, kernel_size = (2, 2),\n",
    "                strides = 1,activation = 'relu', padding = 'same'))\n",
    "model.add(MaxPool2D((2, 2), 2, padding = 'same'))\n",
    "          \n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 128)       3328      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 32)          8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 24)                12312     \n",
      "=================================================================\n",
      "Total params: 319,352\n",
      "Trainable params: 319,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#3.2 Dense and output layers:\n",
    "model.add(Dense(units = 512, activation = 'relu'))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "\n",
    "model.add(Dense(units = 24, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.3 Adding the optimizer, loss and metric:\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26\n",
      "824/824 - 37s - loss: 1.6748 - accuracy: 0.5028 - val_loss: 0.6262 - val_accuracy: 0.7893\n",
      "Epoch 2/26\n",
      "824/824 - 42s - loss: 0.3446 - accuracy: 0.8804 - val_loss: 0.1100 - val_accuracy: 0.9665\n",
      "Epoch 3/26\n",
      "824/824 - 36s - loss: 0.1503 - accuracy: 0.9504 - val_loss: 0.0475 - val_accuracy: 0.9837\n",
      "Epoch 4/26\n",
      "824/824 - 38s - loss: 0.1208 - accuracy: 0.9603 - val_loss: 0.0237 - val_accuracy: 0.9924\n",
      "Epoch 5/26\n",
      "824/824 - 40s - loss: 0.1204 - accuracy: 0.9626 - val_loss: 0.0612 - val_accuracy: 0.9811\n",
      "Epoch 6/26\n",
      "824/824 - 35s - loss: 0.1096 - accuracy: 0.9667 - val_loss: 0.0886 - val_accuracy: 0.9698\n",
      "Epoch 7/26\n",
      "824/824 - 36s - loss: 0.1000 - accuracy: 0.9716 - val_loss: 0.0266 - val_accuracy: 0.9910\n",
      "Epoch 8/26\n",
      "824/824 - 38s - loss: 0.0678 - accuracy: 0.9790 - val_loss: 0.0227 - val_accuracy: 0.9921\n",
      "Epoch 9/26\n",
      "824/824 - 39s - loss: 0.0982 - accuracy: 0.9723 - val_loss: 0.0150 - val_accuracy: 0.9964\n",
      "Epoch 10/26\n",
      "824/824 - 37s - loss: 0.0810 - accuracy: 0.9783 - val_loss: 0.0286 - val_accuracy: 0.9911\n",
      "Epoch 11/26\n",
      "824/824 - 36s - loss: 0.0531 - accuracy: 0.9848 - val_loss: 0.0404 - val_accuracy: 0.9873\n",
      "Epoch 12/26\n",
      "824/824 - 36s - loss: 0.1175 - accuracy: 0.9714 - val_loss: 0.0098 - val_accuracy: 0.9971\n",
      "Epoch 13/26\n",
      "824/824 - 36s - loss: 0.0426 - accuracy: 0.9893 - val_loss: 0.0074 - val_accuracy: 0.9972\n",
      "Epoch 14/26\n",
      "824/824 - 36s - loss: 0.0857 - accuracy: 0.9801 - val_loss: 0.0825 - val_accuracy: 0.9781\n",
      "Epoch 15/26\n",
      "824/824 - 36s - loss: 0.0860 - accuracy: 0.9803 - val_loss: 0.0109 - val_accuracy: 0.9969\n",
      "Epoch 16/26\n",
      "824/824 - 36s - loss: 0.0488 - accuracy: 0.9884 - val_loss: 0.0304 - val_accuracy: 0.9916\n",
      "Epoch 17/26\n",
      "824/824 - 36s - loss: 0.0824 - accuracy: 0.9832 - val_loss: 0.0359 - val_accuracy: 0.9908\n",
      "Epoch 18/26\n",
      "824/824 - 38s - loss: 0.0875 - accuracy: 0.9820 - val_loss: 0.0166 - val_accuracy: 0.9946\n",
      "Epoch 19/26\n",
      "824/824 - 37s - loss: 0.0499 - accuracy: 0.9902 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
      "Epoch 20/26\n",
      "824/824 - 36s - loss: 0.0873 - accuracy: 0.9821 - val_loss: 0.0407 - val_accuracy: 0.9897\n",
      "Epoch 21/26\n",
      "824/824 - 36s - loss: 0.0461 - accuracy: 0.9900 - val_loss: 0.0246 - val_accuracy: 0.9965\n",
      "Epoch 22/26\n",
      "824/824 - 36s - loss: 0.0825 - accuracy: 0.9843 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 23/26\n",
      "824/824 - 35s - loss: 0.0606 - accuracy: 0.9889 - val_loss: 0.0156 - val_accuracy: 0.9958\n",
      "Epoch 24/26\n",
      "824/824 - 35s - loss: 0.0923 - accuracy: 0.9848 - val_loss: 0.0237 - val_accuracy: 0.9924\n",
      "Epoch 25/26\n",
      "824/824 - 37s - loss: 0.0630 - accuracy: 0.9895 - val_loss: 0.0172 - val_accuracy: 0.9972\n",
      "Epoch 26/26\n",
      "824/824 - 35s - loss: 0.1007 - accuracy: 0.9852 - val_loss: 0.0140 - val_accuracy: 0.9961\n"
     ]
    }
   ],
   "source": [
    "#4. TRAINING THE CNN MODEL\n",
    "history = model.fit(X_train, Y_train, batch_size = 25,\n",
    "                    epochs = 26,\n",
    "                    verbose = 2,\n",
    "                    validation_data = (X_val, Y_val)\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "def predict_image(img, model):\n",
    "    classes = lb.classes_\n",
    "    X = img.reshape((28*28, )).reshape(-1, 28, 28, 1)\n",
    "    Y_pred = model.predict(X, batch_size = 25)\n",
    "    Y_pred_class_index = np.argmax(Y_pred, axis = 1)\n",
    "    Y_pred_class = np.take(classes, Y_pred_class_index)\n",
    "    return Y_pred_class[0]\n",
    "predict_image(i4, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19181012', '2423142413', '3201617', '22318819', '21214', '2007717', '121523205', '019220', '158615', '33112211']\n"
     ]
    }
   ],
   "source": [
    "predict_data = np.load('test_images_task2.npy')\n",
    "all_prediction = []\n",
    "for i in range (predict_data.shape[0]):\n",
    "    # step 1: delete background and split each image\n",
    "    \n",
    "    long_img = predict_data[i].astype(\"int\")   #select each image\n",
    "    mode, count = stats.mode(long_img, axis = 0)   # the mode of background is 200\n",
    "    condition = (mode == 200)\n",
    "    index = np.where(np.any(condition == True, axis=0))[0]    # find the index of the 200\n",
    "    delete_noise = np.delete(long_img, index, axis=1)         # delete all the 200\n",
    "    if delete_noise.shape[1] % 28 == 0:                    # check if the long image can be splitted into images with width of 28\n",
    "        n_pic = int(delete_noise.shape[1]/28)                 # the number of pics in one original image\n",
    "        splitted = np.array(np.hsplit(delete_noise, n_pic))   # split the long image into n_pic images, store in an array\n",
    "    else:\n",
    "        row_not_fit = round(delete_noise.shape[1]/28) * 28 - delete_noise.shape[1]\n",
    "        n_pic = round(delete_noise.shape[1]/28)\n",
    "        if row_not_fit > 0:\n",
    "            to_add = np.full((28, row_not_fit), 255)\n",
    "            delete_noise = np.append(delete_noise, to_add, axis=1)\n",
    "            splitted = np.array(np.hsplit(delete_noise, n_pic))\n",
    "        if row_not_fit < 0:\n",
    "            delete_noise = delete_noise[:, :-row_not_fit]\n",
    "            splitted = np.array(np.hsplit(delete_noise, n_pic))\n",
    "\n",
    "    # step 2: do prediction on each image in \"splitted\", and save the result in one array for each long image\n",
    "    each_image = \"\"\n",
    "    for img in splitted:\n",
    "        # (note: i transfer to tensor data, but please use your cnn way to do this step)\n",
    "        prediction = predict_image(img, model)    #also put your cnn model here to predict\n",
    "        each_image += str(prediction)\n",
    "    all_prediction.append(each_image)\n",
    "    \n",
    "print(all_prediction[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_prediction = np.array(all_prediction)\n",
    "CNN_prediction = pd.DataFrame(all_prediction)\n",
    "CNN_prediction.to_csv(\"CNN_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
